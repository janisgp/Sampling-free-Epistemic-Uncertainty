{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from src.datasets import camvid\n",
    "from src import evaluate\n",
    "from src import plot\n",
    "from src import predict\n",
    "from src import segnet\n",
    "from src.callbacks import PlotMetrics\n",
    "from src.utils import history_to_results\n",
    "\n",
    "from uncertainty_propagator.uncertainty_propagator import UncertaintyPropagator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'models/SegNet-CamVid11-Bayesian.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the batch size for training the network\n",
    "batch_size = 1\n",
    "# the size to crop images to\n",
    "crop_size = (352, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images once\n",
    "camvid11 = camvid.CamVid(\n",
    "    mapping=camvid.CamVid.load_mapping(), \n",
    "    target_size=(360, 480), \n",
    "    crop_size=crop_size, \n",
    "    batch_size=batch_size,\n",
    "    ignored_labels=['Void'],\n",
    ")\n",
    "generators = camvid11.generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the next X, y training tuple\n",
    "X, y = next(generators['train'])\n",
    "# transform the onehot vector to an image\n",
    "y = camvid11.unmap(y)\n",
    "# plot the images\n",
    "_ = plot.plot_list([X[0], y[0]], ['X', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we hold out classes during training we mask the loss of the corresponding classes (here: pedestrians and cyclist). We use two types of architectures: EncDecCenter -> dropout after the central 4 encoder and decoder blocks; Class -> dropout only prior to the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_pedestrian = False\n",
    "hold_out_byciclist = False\n",
    "\n",
    "class_weights = camvid11.class_weights\n",
    "if hold_out_pedestrian:\n",
    "    class_weights[5] = 0\n",
    "if hold_out_byciclist: \n",
    "    class_weights[0] = 0\n",
    "\n",
    "# Alternatives: EncDecCenter & Class\n",
    "dropout_location = 'EncDecCenter' \n",
    "drop_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model for the image shape and number of labels\n",
    "model = segnet.segnet((*crop_size, 3), camvid11.n, \n",
    "    class_weights=camvid11.class_weights,\n",
    "    dropout_rate=drop_rate,\n",
    "    dropout_loc=dropout_location,\n",
    "    bn_train=False\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the callbacks for the training procedure\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='loss', patience=50),\n",
    "    LearningRateScheduler(lambda _, lr: 0.95 * lr),\n",
    "    ModelCheckpoint(weights_file, \n",
    "        monitor='val_categorical_accuracy', \n",
    "        save_best_only=True, \n",
    "        save_weights_only=True, \n",
    "        mode='max'\n",
    "    ),\n",
    "    PlotMetrics(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model with the data. divide the steps per epoch by the \n",
    "# batch size (which is 3 in this case)\n",
    "history = model.fit_generator(generators['train'],\n",
    "    epochs=200,\n",
    "    steps_per_epoch=int(367 / batch_size),\n",
    "    validation_data=generators['val'],\n",
    "    validation_steps=101,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_to_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the variance propagation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust keras model for variance propagation\n",
    "unc_prop = UncertaintyPropagator(model, mc_samples=10)\n",
    "_ = unc_prop.build_model(exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_mc = False\n",
    "\n",
    "# define whether to use mc predictions or our approximation\n",
    "unc_prop.set_mc_mode(use_mc)\n",
    "\n",
    "# compute metrics, callibration data, holdout uncertainty (if class hold out) and uncertainty per class\n",
    "metrics, callibration_data, hold_out_uncertainty, unc_per_class = evaluate.evaluate(unc_prop, generators['test'], 233,\n",
    "    mask=camvid11.class_mask, \n",
    "    code_map=camvid11.discrete_to_label_map\n",
    ")\n",
    "\n",
    "metrics_file_name = weights_file + '.csv' if use_mc else weights_file + '_our.csv'\n",
    "metrics.to_csv(metrics_file_name)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following creates a callibration plot. Thus uncertainty against the misclassification rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(callibration_data[0], callibration_data[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, res = predict.predict_epistemic_all(unc_prop, generators['train'], camvid11)\n",
    "_ = plot.plot_list([X[0], y[0], res['mc'][0][0], res['approx'][0][0], res['mc'][1][0], res['approx'][1][0]], \n",
    "              ['X', 'y_true', 'y_pred_mc', 'y_pred_ours', 'uncertainty_mc', 'uncertainty_our'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, res = predict.predict_epistemic_all(unc_prop, generators['val'], camvid11)\n",
    "_ = plot.plot_list([X[0], y[0], res['mc'][0][0], res['approx'][0][0], res['mc'][1][0], res['approx'][1][0]], \n",
    "              ['X', 'y_true', 'y_pred_mc', 'y_pred_ours', 'uncertainty_mc', 'uncertainty_our'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, res = predict.predict_epistemic_all(unc_prop, generators['test'], camvid11)\n",
    "_ = plot.plot_list([X[0], y[0], res['mc'][0][0], res['approx'][0][0], res['mc'][1][0], res['approx'][1][0]], \n",
    "              ['X', 'y_true', 'y_pred_mc', 'y_pred_ours', 'uncertainty_mc', 'uncertainty_our'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (segnet2)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
